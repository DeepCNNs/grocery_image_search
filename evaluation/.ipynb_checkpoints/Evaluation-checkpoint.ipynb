{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from enum import Enum\n",
    "import cv2\n",
    "import numpy as np\n",
    "from time import time\n",
    "import sys\n",
    "sys.path.insert(0, \"/home/adity/Desktop/projects/image_search/code/classifiers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YType(Enum):\n",
    "    SAME = 0\n",
    "    DIFFERENT = 1\n",
    "    NONE = 2\n",
    "\n",
    "class TestDataStructure:\n",
    "    clientA = ''\n",
    "    clientB = ''\n",
    "    expected_y = YType.NONE\n",
    "    predicted_y = YType.NONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Evaluation:\n",
    "    def __init__(self, model=None, enable_accuracy=False, enable_auc=False, enable_confusion_matrix=False, enable_precision=False, enable_recall=False):\n",
    "        self.model = model\n",
    "        self.enable_accuracy = enable_accuracy\n",
    "        self.enable_auc = enable_auc\n",
    "        self.enable_confusion_matrix = enable_confusion_matrix\n",
    "        self.enable_precision = enable_precision\n",
    "        self.enable_recall = enable_recall\n",
    "        self.dataset_path = \"/home/adity/Desktop/projects/image_search/datasets/Test Data/\"\n",
    "        # no f1\n",
    "        \n",
    "    def prepare_test_Data(self, csv_file):\n",
    "        list_A = []\n",
    "        list_B = []\n",
    "        line_number = 0\n",
    "        with open(csv_file, 'r') as file:\n",
    "            reader = csv.reader(file)\n",
    "            for row in reader:\n",
    "                if line_number == 0:\n",
    "                    line_number += 1\n",
    "                else:\n",
    "                    if row[0] == '':\n",
    "                        print()\n",
    "                        list_A.append(None)\n",
    "                    else:\n",
    "                        list_A.append(row[0])\n",
    "                    \n",
    "                    if row[1] == '':\n",
    "                        list_B.append(None)\n",
    "                    else:\n",
    "                        list_B.append(row[1])\n",
    "                    line_number += 1\n",
    "        print(\"Processed lines\", {line_number})\n",
    "        return list_A, list_B\n",
    "    \n",
    "    def prepare_test_data_Structure(self, list_A, list_B):\n",
    "        test_data_list = []\n",
    "        i = 0\n",
    "        for item_A in list_A:\n",
    "            j = 0\n",
    "            for item_B in list_B:\n",
    "                test_data = TestDataStructure()\n",
    "                test_data.clientA = list_A[i]\n",
    "                test_data.clientB = list_B[j]\n",
    "                if i == j:\n",
    "                    if list_A[i] and list_B[j]:\n",
    "                        test_data.expected_y = YType.SAME\n",
    "                    test_data_list.append(test_data)\n",
    "                else:\n",
    "                    if list_A[i] and list_B[j]:\n",
    "                        test_data.expected_y = YType.DIFFERENT\n",
    "                        test_data_list.append(test_data)\n",
    "                j += 1\n",
    "            i += 1\n",
    "        return test_data_list\n",
    "    \n",
    "    def generate_output_lists(self, test_data_list):\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "        i = 0\n",
    "        for test_data in test_data_list:\n",
    "            y_true.append(test_data.expected_y.value)\n",
    "            y_pred.append(test_data.predicted_y.value)\n",
    "            i += 1\n",
    "        return y_true, y_pred\n",
    "    \n",
    "    def get_results_for_all_image_pairs(self, test_data_list, model):\n",
    "        for test_data in test_data_list:\n",
    "            if test_data.clientA != None and test_data.clientB != None:\n",
    "                image_1 = cv2.imread(self.dataset_path + \"Client1/\" + test_data.clientA)\n",
    "                image_2 = cv2.imread(self.dataset_path + \"Client2/\" + test_data.clientB)\n",
    "                if type(image_1) == np.ndarray and type(image_2) == np.ndarray:\n",
    "                    image_1 = cv2.resize(image_1, (250,250))\n",
    "                    image_2 = cv2.resize(image_2, (250,250))\n",
    "                    tic = time()\n",
    "                    test_data.predicted_y = model.compare_image(image_1, image_2)\n",
    "                    toc = time()\n",
    "#                     print(test_data.clientA, test_data.clientB, \", Expected Y:\" + str(test_data.expected_y), \", Predicted y:\", str(test_data.predicted_y), \"time taken:\", toc - tic)\n",
    "\n",
    "    def get_results_for_all_image_pairs_color(self, test_data_list, model):\n",
    "        for test_data in test_data_list:\n",
    "            if test_data.clientA != None and test_data.clientB != None:\n",
    "                image_1 = cv2.imread(self.dataset_path + \"Client1/\" + test_data.clientA)\n",
    "                image_2 = cv2.imread(self.dataset_path + \"Client2/\" + test_data.clientB)\n",
    "                if type(image_1) == np.ndarray and type(image_2) == np.ndarray:\n",
    "                    image_1 = cv2.resize(image_1, (250,250))\n",
    "                    image_2 = cv2.resize(image_2, (250,250))\n",
    "                    tic = time()\n",
    "                    test_data.predicted_y = model.compare_image(image_1, image_2)\n",
    "                    toc = time()\n",
    "                    print(test_data.clientA, test_data.clientB, \", Expected Y:\" + str(test_data.expected_y), \", Predicted y:\", str(test_data.predicted_y), \"time taken:\", toc - tic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_model = Evaluation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed lines {496}\n",
      "['akin fragrance free conditioner 500'].jpg ['Alberto Balsam Juicy Green Apple Shampoo  350ml'].jpg YType.DIFFERENT YType.NONE\n",
      "164009\n"
     ]
    }
   ],
   "source": [
    "list_A, list_B = eval_model.prepare_test_Data(\"/home/adity/Desktop/projects/image_search/datasets/Test Data/match.csv\")\n",
    "test_data = eval_model.prepare_test_data_Structure(list_A, list_B)\n",
    "print(test_data[1].clientA, test_data[1].clientB, test_data[1].expected_y, test_data[1].predicted_y)\n",
    "print(len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['akin fragrance free conditioner 500'].jpg ['Alberto Balsam Juicy Green Apple Shampoo  350ml'].jpg YType.DIFFERENT YType.NONE\n"
     ]
    }
   ],
   "source": [
    "print(test_data[1].clientA, test_data[1].clientB, test_data[1].expected_y, test_data[1].predicted_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"/home/adity/Desktop/projects/image_search/code/classifiers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from template_matching import TemplateMatching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "tm = TemplateMatching(0.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_model.get_results_for_all_image_pairs(test_data, tm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true, y_pred = eval_model.generate_output_lists(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00364283 1.         0.24886191]\n"
     ]
    }
   ],
   "source": [
    "print(precision_score(y_true, y_pred, average=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99697885, 0.4449833 , 1.        ])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_true, y_pred, average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00725913, 0.61590096, 0.39854192])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_true, y_pred, average=None)\n",
    "# SAME, DIFFERENT, NONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mse import MSEComparator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_c = MSEComparator(0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed lines {496}\n",
      "['akin fragrance free conditioner 500'].jpg ['Alberto Balsam Juicy Green Apple Shampoo  350ml'].jpg YType.DIFFERENT YType.NONE\n",
      "164009\n"
     ]
    }
   ],
   "source": [
    "eval_model = Evaluation()\n",
    "list_A, list_B = eval_model.prepare_test_Data(\"/home/adity/Desktop/projects/image_search/datasets/Test Data/match.csv\")\n",
    "test_data = eval_model.prepare_test_data_Structure(list_A, list_B)\n",
    "print(test_data[1].clientA, test_data[1].clientB, test_data[1].expected_y, test_data[1].predicted_y)\n",
    "print(len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_model.get_results_for_all_image_pairs(test_data, mse_c)\n",
    "y_true, y_pred = eval_model.generate_output_lists(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.918429  , 0.99675869, 1.        ])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_true, y_pred, average=None)\n",
    "# tp / (tp + fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.89411765, 0.9998405 , 0.24886191])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_true, y_pred, average=None)\n",
    "# tp / (tp + fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.90611028, 0.99829722, 0.39854192])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_true, y_pred, average=None)\n",
    "# SAME, DIFFERENT, NONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ssim import SSIMComparator\n",
    "ssim_c = SSIMComparator(0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed lines {496}\n",
      "['akin fragrance free conditioner 500'].jpg ['Alberto Balsam Juicy Green Apple Shampoo  350ml'].jpg YType.DIFFERENT YType.NONE\n",
      "164009\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-b2679a0d0a62>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclientA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclientB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpected_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredicted_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0meval_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_results_for_all_image_pairs_color\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mssim_c\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_output_lists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-8920e9984a6f>\u001b[0m in \u001b[0;36mget_results_for_all_image_pairs_color\u001b[0;34m(self, test_data_list, model)\u001b[0m\n\u001b[1;32m     87\u001b[0m                     \u001b[0mimage_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m250\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m250\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                     \u001b[0mtic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                     \u001b[0mtest_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredicted_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompare_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m                     \u001b[0mtoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/adity/Desktop/projects/image_search/code/classifiers/ssim.py\u001b[0m in \u001b[0;36mcompare_image\u001b[0;34m(self, imageA, imageB)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcompare_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimageA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimageB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructural_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimageA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimageB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultichannel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mYType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSAME\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/skimage/metrics/_structural_similarity.py\u001b[0m in \u001b[0;36mstructural_similarity\u001b[0;34m(im1, im2, win_size, gradient, data_range, multichannel, gaussian_weights, full, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m             ch_result = structural_similarity(im1[..., ch],\n\u001b[0;32m--> 108\u001b[0;31m                                               im2[..., ch], **args)\n\u001b[0m\u001b[1;32m    109\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mgradient\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfull\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m                 \u001b[0mmssim\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mch\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mch_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/skimage/metrics/_structural_similarity.py\u001b[0m in \u001b[0;36mstructural_similarity\u001b[0;34m(im1, im2, win_size, gradient, data_range, multichannel, gaussian_weights, full, **kwargs)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0;31m# compute (weighted) variances and covariances\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m     \u001b[0muxx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilter_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mim1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfilter_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m     \u001b[0muyy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilter_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mim2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfilter_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0muxy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilter_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mim2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfilter_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/scipy/ndimage/filters.py\u001b[0m in \u001b[0;36muniform_filter\u001b[0;34m(input, size, output, mode, cval, origin)\u001b[0m\n\u001b[1;32m    825\u001b[0m     \"\"\"\n\u001b[1;32m    826\u001b[0m     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 827\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ni_support\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    828\u001b[0m     \u001b[0msizes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ni_support\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_normalize_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    829\u001b[0m     \u001b[0morigins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ni_support\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_normalize_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morigin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/scipy/ndimage/_ni_support.py\u001b[0m in \u001b[0;36m_get_output\u001b[0;34m(output, input, shape)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "eval_model = Evaluation()\n",
    "list_A, list_B = eval_model.prepare_test_Data(\"/home/adity/Desktop/projects/image_search/datasets/Test Data/match.csv\")\n",
    "test_data = eval_model.prepare_test_data_Structure(list_A, list_B)\n",
    "print(test_data[1].clientA, test_data[1].clientB, test_data[1].expected_y, test_data[1].predicted_y)\n",
    "print(len(test_data))\n",
    "eval_model.get_results_for_all_image_pairs_color(test_data, ssim_c)\n",
    "y_true, y_pred = eval_model.generate_output_lists(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.918429  , 0.99675869, 1.        ])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_true, y_pred, average=None)\n",
    "# tp / (tp + fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.89411765, 0.9998405 , 0.24886191])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_true, y_pred, average=None)\n",
    "# tp / (tp + fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.90611028, 0.99829722, 0.39854192])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_true, y_pred, average=None)\n",
    "# SAME, DIFFERENT, NONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vgg16 import FeatureExtractor\n",
    "vgg = FeatureExtractor(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_model = Evaluation()\n",
    "list_A, list_B = eval_model.prepare_test_Data(\"/home/adity/Desktop/projects/image_search/datasets/Test Data/match.csv\")\n",
    "test_data = eval_model.prepare_test_data_Structure(list_A, list_B)\n",
    "print(test_data[1].clientA, test_data[1].clientB, test_data[1].expected_y, test_data[1].predicted_y)\n",
    "print(len(test_data))\n",
    "eval_model.get_results_for_all_image_pairs(test_data, mse_c)\n",
    "y_true, y_pred = eval_model.generate_output_lists(test_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
